services:
  llm-host:
    build:
      context: .
    container_name: llm-host
    entrypoint: sleep infinity
    volumes:
      - ./app:/app
      - ./models:/models
    ports:
      - "8000:8000"
    networks:
      - llm-network
    gpu: all
networks:
  llm-network:
    # Specify driver options
    driver: bridge
